# comp_torch_tensorRT
In this repository, we want to compare inference time of two models torch and TensorRT. We used COCO dataset.
# Run
We implemented our code in `YOLOv5.ipynb`


# Result
in the following table, we show inference time (ms) of two models `torch` and `TensorRT`.  

<table>
 <tr>
 <td>"Torch"</td>
 <td>"tensorRT"</td>
 </tr>
 <tr>
 <td> "13.0" </td>
 <td> "10.8" </td>
 </tr>
</table>
    
